{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ9rBKmHQEgg",
        "outputId": "73338d23-12e2-4def-ff14-1f76f4d3acf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
            "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
            "  warnings.warn(\"xFormers is not available (Attention)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
            "  warnings.warn(\"xFormers is not available (Block)\")\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vits14/dinov2_vits14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vits14_pretrain.pth\n",
            "100%|██████████| 84.2M/84.2M [00:00<00:00, 192MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:02<00:00, 4303807.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 129726.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:05<00:00, 277275.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4509000.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True,\n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # Repeat grayscale channel 3 times\n",
        "                               ]))\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True,\n",
        "                              transform=transforms.Compose([\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # Repeat grayscale channel 3 times\n",
        "                              ]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKtcxbBePoJS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcXU831WPwX5"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "features, labels_list = [],[]\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for data, labels in train_loader:\n",
        "    data = data.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      out = model(data)\n",
        "\n",
        "    features.append(out.cpu())\n",
        "    labels_list.append(labels.cpu())\n",
        "\n",
        "features = torch.cat(features, dim=0)\n",
        "labels_list = torch.cat(labels_list, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Hq2CjVVQRwQ"
      },
      "outputs": [],
      "source": [
        "train_features = torch.utils.data.TensorDataset(features, labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTO8GL_ikhC-"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "features, labels_list = [],[]\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for data, labels in test_loader:\n",
        "    data = data.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      out = model(data)\n",
        "\n",
        "    features.append(out.cpu())\n",
        "    labels_list.append(labels.cpu())\n",
        "\n",
        "features = torch.cat(features, dim=0)\n",
        "labels_list = torch.cat(labels_list, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufvKDgu4ku6n"
      },
      "outputs": [],
      "source": [
        "test_features = torch.utils.data.TensorDataset(features, labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx6a9zlSkE9O"
      },
      "outputs": [],
      "source": [
        "with open(\"vit_train_features\", \"wb\") as f:\n",
        "    torch.save(train_features, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1cLxyQGk38L"
      },
      "outputs": [],
      "source": [
        "with open(\"vit_test_features\", \"wb\") as f:\n",
        "    torch.save(test_features, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
